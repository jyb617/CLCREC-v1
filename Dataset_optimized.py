"""
ä¼˜åŒ–ç‰ˆæ•°æ®é›† - é¢„ç”Ÿæˆè´Ÿæ ·æœ¬ä»¥åŠ é€Ÿè®­ç»ƒ

ä¸»è¦ä¼˜åŒ–ï¼š
1. é¢„ç”Ÿæˆæ‰€æœ‰è´Ÿæ ·æœ¬ï¼Œé¿å…æ¯æ¬¡ __getitem__ æ—¶è¿›è¡ŒCPUé‡‡æ ·
2. æ”¯æŒå®šæœŸé‡æ–°é‡‡æ ·ä»¥ä¿æŒéšæœºæ€§
3. æ˜¾è‘—å‡å°‘é›†åˆè¿ç®—å¼€é”€
"""

import time
import random
import numpy as np
import os
import torch
from torch.utils.data import Dataset
from tqdm import tqdm


class TrainingDatasetOptimized(Dataset):
    """ä¼˜åŒ–ç‰ˆè®­ç»ƒæ•°æ®é›† - é¢„ç”Ÿæˆè´Ÿæ ·æœ¬"""

    def __init__(self, num_user, num_item, user_item_dict, dataset, train_data, num_neg,
                 resample_epochs=5):
        """
        Args:
            resample_epochs: æ¯éš”å¤šå°‘ä¸ªepoché‡æ–°ç”Ÿæˆè´Ÿæ ·æœ¬ï¼ˆé»˜è®¤5ï¼‰
                            è®¾ä¸º0è¡¨ç¤ºåªç”Ÿæˆä¸€æ¬¡
        """
        self.train_data = train_data
        self.num_user = num_user
        self.num_item = num_item
        self.num_neg = num_neg
        self.user_item_dict = user_item_dict
        self.resample_epochs = resample_epochs
        self.current_epoch = 0

        cold_set_path = './Data/' + dataset + '/cold_set.npy'
        if os.path.exists(cold_set_path):
            self.cold_set = set(np.load(cold_set_path))
        else:
            print(f"âš  cold_set.npy ä¸å­˜åœ¨ï¼Œå‡è®¾æ‰€æœ‰ç‰©å“éƒ½æ˜¯warm")
            self.cold_set = set()

        self.all_set = set(range(num_user, num_user + num_item)) - self.cold_set

        # ğŸš€ é¢„ç”Ÿæˆè´Ÿæ ·æœ¬
        print("\nğŸš€ é¢„ç”Ÿæˆè´Ÿæ ·æœ¬ä»¥åŠ é€Ÿè®­ç»ƒ...")
        self.negative_samples = None
        self.generate_negative_samples()

    def generate_negative_samples(self):
        """é¢„ç”Ÿæˆæ‰€æœ‰è´Ÿæ ·æœ¬"""
        start_time = time.time()

        self.negative_samples = []

        print(f"   ç”Ÿæˆ {len(self.train_data)} ä¸ªæ ·æœ¬çš„è´Ÿæ ·æœ¬ (num_neg={self.num_neg})...")

        for user, pos_item in tqdm(self.train_data, desc="   Generating negatives", ncols=80):
            user = int(user)
            # å€™é€‰è´Ÿæ ·æœ¬é›†åˆ
            candidate_set = self.all_set - set(self.user_item_dict[user])
            # é‡‡æ ·
            neg_items = random.sample(candidate_set, self.num_neg)
            self.negative_samples.append(neg_items)

        elapsed = time.time() - start_time
        print(f"âœ“ è´Ÿæ ·æœ¬ç”Ÿæˆå®Œæˆï¼è€—æ—¶: {elapsed:.2f}s")
        print(f"   è¿™ä¸ªå¼€é”€åœ¨æ•´ä¸ªè®­ç»ƒä¸­åªéœ€è¦ä»˜å‡ºä¸€æ¬¡ï¼ˆæˆ–æ¯{self.resample_epochs}ä¸ªepochä¸€æ¬¡ï¼‰\n")

    def resample_if_needed(self, epoch):
        """æ ¹æ®éœ€è¦é‡æ–°ç”Ÿæˆè´Ÿæ ·æœ¬"""
        if self.resample_epochs > 0 and epoch % self.resample_epochs == 0 and epoch > 0:
            print(f"\n>>> Epoch {epoch}: é‡æ–°ç”Ÿæˆè´Ÿæ ·æœ¬...")
            self.generate_negative_samples()
        self.current_epoch = epoch

    def __len__(self):
        return len(self.train_data)

    def __getitem__(self, index):
        user, pos_item = self.train_data[index]

        # ğŸ”§ ä¿®å¤ï¼šå°†numpyç±»å‹è½¬æ¢ä¸ºPython int
        user = int(user)
        pos_item = int(pos_item)

        # ğŸš€ ç›´æ¥ä½¿ç”¨é¢„ç”Ÿæˆçš„è´Ÿæ ·æœ¬ï¼ˆè¶…å¿«ï¼ï¼‰
        neg_items = self.negative_samples[index]

        # åˆ›å»ºå¼ é‡
        user_tensor = torch.LongTensor([user] * (self.num_neg + 1))
        item_tensor = torch.LongTensor([pos_item] + neg_items)

        return user_tensor, item_tensor


class TrainingDatasetGPU(Dataset):
    """GPUç‰ˆè®­ç»ƒæ•°æ®é›† - åœ¨GPUä¸Šé‡‡æ ·ï¼ˆå®éªŒæ€§ï¼‰"""

    def __init__(self, num_user, num_item, user_item_dict, dataset, train_data, num_neg):
        """
        å®éªŒæ€§ç‰ˆæœ¬ï¼šå°è¯•åœ¨GPUä¸Šè¿›è¡Œè´Ÿé‡‡æ ·
        æ³¨æ„ï¼šå¯èƒ½ä¸ç¨³å®šï¼Œéœ€è¦æ›´å¤šæµ‹è¯•
        """
        self.train_data = train_data
        self.num_user = num_user
        self.num_item = num_item
        self.num_neg = num_neg
        self.user_item_dict = user_item_dict

        cold_set_path = './Data/' + dataset + '/cold_set.npy'
        if os.path.exists(cold_set_path):
            self.cold_set = set(np.load(cold_set_path))
        else:
            self.cold_set = set()

        self.all_items = torch.tensor(
            list(set(range(num_user, num_user + num_item)) - self.cold_set),
            dtype=torch.long,
            device='cuda'
        )

        # é¢„è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„æ­£æ ·æœ¬mask
        print("\nğŸš€ é¢„è®¡ç®—ç”¨æˆ·-ç‰©å“mask...")
        self.user_pos_masks = {}
        for user in tqdm(range(num_user), desc="   Building masks", ncols=80):
            if user in user_item_dict:
                pos_items = torch.tensor(
                    list(user_item_dict[user]),
                    dtype=torch.long,
                    device='cuda'
                )
                # åˆ›å»ºmask
                mask = torch.ones(len(self.all_items), dtype=torch.bool, device='cuda')
                for item in pos_items:
                    item_idx = (self.all_items == item).nonzero(as_tuple=True)[0]
                    if len(item_idx) > 0:
                        mask[item_idx[0]] = False
                self.user_pos_masks[user] = mask

        print("âœ“ Maské¢„è®¡ç®—å®Œæˆï¼\n")

    def __len__(self):
        return len(self.train_data)

    def __getitem__(self, index):
        user, pos_item = self.train_data[index]
        user = int(user)
        pos_item = int(pos_item)

        # ğŸš€ åœ¨GPUä¸Šé‡‡æ ·
        if user in self.user_pos_masks:
            mask = self.user_pos_masks[user]
            candidate_items = self.all_items[mask]

            # GPUä¸Šéšæœºé‡‡æ ·
            perm = torch.randperm(len(candidate_items), device='cuda')[:self.num_neg]
            neg_items = candidate_items[perm].cpu().tolist()
        else:
            # fallback to CPU
            neg_items = random.sample(
                list(set(range(self.num_user, self.num_user + self.num_item)) - self.cold_set),
                self.num_neg
            )

        user_tensor = torch.LongTensor([user] * (self.num_neg + 1))
        item_tensor = torch.LongTensor([pos_item] + neg_items)

        return user_tensor, item_tensor


# ä¿æŒåŸå§‹ç‰ˆæœ¬ä»¥ä¾¿å…¼å®¹
from Dataset import TrainingDataset as TrainingDatasetOriginal


def benchmark_datasets(num_samples=1000):
    """å¯¹æ¯”æµ‹è¯•ä¸åŒæ•°æ®é›†å®ç°çš„é€Ÿåº¦"""
    print("\n" + "=" * 80)
    print("æ•°æ®é›†æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("=" * 80)

    # è¿™é‡Œéœ€è¦å®é™…çš„æ•°æ®æ¥æµ‹è¯•
    # ä»…ä½œä¸ºç¤ºä¾‹ä»£ç 
    print("\nè¿è¡Œæ–¹æ³•ï¼š")
    print("1. åœ¨ main.py ä¸­å¯¼å…¥: from Dataset_optimized import TrainingDatasetOptimized")
    print("2. æ›¿æ¢æ•°æ®é›†åˆ›å»ºä»£ç ")
    print("3. è§‚å¯Ÿè®­ç»ƒé€Ÿåº¦æå‡")


if __name__ == '__main__':
    benchmark_datasets()
