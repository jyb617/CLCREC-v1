from tqdm import tqdm
import numpy as np
import torch
import torch.nn as nn
from torch.nn import Parameter
import torch.nn.functional as F


##########################################################################
# æ”¹è¿›çš„ scatter mean å®ç°ï¼ˆä½¿ç”¨ PyTorch åŸç”Ÿæ“ä½œï¼Œé¿å…å¾ªç¯ï¼‰
##########################################################################

def scatter_mean_manual(src, index, dim=0):
    """
    é«˜æ•ˆçš„ scatter mean å®ç°ï¼Œæ›¿ä»£ torch_scatter.scatter

    Args:
        src: æºå¼ é‡ [N, D]
        index: ç´¢å¼•å¼ é‡ [N]
        dim: èšåˆç»´åº¦

    Returns:
        out: èšåˆåçš„å¼ é‡ [max(index)+1, D]
    """
    if src.size(0) == 0:
        return src

    num_nodes = index.max().item() + 1
    out = torch.zeros(num_nodes, src.size(1), dtype=src.dtype, device=src.device)
    count = torch.zeros(num_nodes, 1, dtype=torch.float, device=src.device)

    # ä½¿ç”¨ scatter_add_ è¿›è¡Œç´¯åŠ ï¼ˆæ¯”å¾ªç¯å¿«å¾—å¤šï¼‰
    out.scatter_add_(0, index.unsqueeze(1).expand(-1, src.size(1)), src)
    count.scatter_add_(0, index.unsqueeze(1), torch.ones_like(index, dtype=torch.float).unsqueeze(1))

    # è®¡ç®—å¹³å‡å€¼ï¼Œé¿å…é™¤é›¶
    count = count.clamp(min=1)
    out = out / count

    return out


##########################################################################

class CLCRec(torch.nn.Module):
    def __init__(self, num_user, num_item, num_warm_item, edge_index, reg_weight, dim_E, v_feat, a_feat, t_feat,
                 temp_value, num_neg, lr_lambda, is_word, num_sample=0.5, use_neighbor_loss=False):
        super(CLCRec, self).__init__()
        self.num_user = num_user
        self.num_item = num_item
        self.num_warm_item = num_warm_item
        self.num_neg = num_neg
        self.lr_lambda = lr_lambda
        self.reg_weight = reg_weight
        self.temp_value = temp_value
        self.dim_E = dim_E
        self.is_word = is_word
        self.num_sample = num_sample
        self.use_neighbor_loss = use_neighbor_loss  # ğŸ”§ æ–°å¢ï¼šæ§åˆ¶æ˜¯å¦ä½¿ç”¨é‚»å±…æŸå¤±

        # IDåµŒå…¥
        self.id_embedding = nn.Parameter(nn.init.xavier_normal_(torch.rand((num_user + num_item, dim_E))))
        self.dim_feat = 0

        # å¤šæ¨¡æ€ç‰¹å¾
        if v_feat is not None:
            self.v_feat = F.normalize(v_feat, dim=1)
            self.dim_feat += self.v_feat.size(1)
        else:
            self.v_feat = None

        if a_feat is not None:
            self.a_feat = F.normalize(a_feat, dim=1)
            self.dim_feat += self.a_feat.size(1)
        else:
            self.a_feat = None

        if t_feat is not None:
            if is_word:
                self.t_feat = nn.Parameter(nn.init.xavier_normal_(torch.rand((torch.max(t_feat[1]).item() + 1, 128))))
                self.word_tensor = t_feat
            else:
                self.t_feat = F.normalize(t_feat, dim=1)
            self.dim_feat += self.t_feat.size(1) if not is_word else 128
        else:
            self.t_feat = None

        # ç¼–ç å™¨
        self.encoder_layer1 = nn.Linear(self.dim_feat, 256)
        self.encoder_layer2 = nn.Linear(256, dim_E)

        # ç”¨æˆ·-ç‰©å“äº¤äº’å›¾
        self.build_user_item_graph(edge_index)

        self.result = nn.init.xavier_normal_(torch.rand((num_user + num_item, dim_E))).cuda()

        # åˆå§‹åŒ–æŸå¤±å˜é‡
        # ğŸ”§ ä¿®å¤ï¼šåœ¨GPUä¸Šåˆ›å»ºtensor
        self.contrastive_loss_1 = torch.tensor(0.0, device='cuda')
        self.contrastive_loss_2 = torch.tensor(0.0, device='cuda')
        self.neighbor_item_loss = torch.tensor(0.0, device='cuda')

    def build_user_item_graph(self, train_data):
        """æ„å»ºç”¨æˆ·-ç‰©å“äº¤äº’å›¾ï¼Œç”¨äºæŸ¥æ‰¾é‚»å±…"""
        # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šå¦‚æœç¦ç”¨é‚»å±…æŸå¤±ï¼Œè·³è¿‡å›¾æ„å»ºä»¥èŠ‚çœåˆå§‹åŒ–æ—¶é—´
        if not self.use_neighbor_loss:
            print("âš ï¸  é‚»å±…æŸå¤±å·²ç¦ç”¨ï¼Œè·³è¿‡ç”¨æˆ·-ç‰©å“å›¾æ„å»ºï¼ˆåŠ é€Ÿåˆå§‹åŒ–ï¼‰")
            self.user_items = {}
            self.item_users = {}
            self.user_neighbors = {}
            return

        self.user_items = {}  # ç”¨æˆ·äº¤äº’çš„ç‰©å“
        self.item_users = {}  # ç‰©å“è¢«å“ªäº›ç”¨æˆ·äº¤äº’

        for user, item in train_data:
            # ğŸ”§ ä¿®å¤ï¼šè½¬æ¢ä¸ºPython int
            user = int(user)
            item = int(item)

            if user not in self.user_items:
                self.user_items[user] = set()
            self.user_items[user].add(item)

            if item not in self.item_users:
                self.item_users[item] = set()
            self.item_users[item].add(user)

        # é¢„è®¡ç®—ç”¨æˆ·é‚»å±…ï¼ˆæœ‰å…±åŒç‰©å“çš„ç”¨æˆ·ï¼‰
        print("Building user neighbor graph...")
        self.user_neighbors = {}
        for user in tqdm(range(self.num_user)):
            neighbors = set()
            if user in self.user_items:
                for item in self.user_items[user]:
                    if item in self.item_users:
                        neighbors.update(self.item_users[item])
                neighbors.discard(user)  # ç§»é™¤è‡ªå·±
            self.user_neighbors[user] = list(neighbors)[:50]  # æœ€å¤š50ä¸ªé‚»å±…

    def encoder(self):
        """ç¼–ç å¤šæ¨¡æ€ç‰¹å¾"""
        feature_list = []

        if self.v_feat is not None:
            feature_list.append(self.v_feat)

        if self.a_feat is not None:
            feature_list.append(self.a_feat)

        if self.t_feat is not None:
            if self.is_word:
                # ä½¿ç”¨æ”¹è¿›çš„ scatter_mean
                # ğŸ”§ ç§»é™¤ä¸å¿…è¦çš„.cuda()ï¼Œscatter_meanè¾“å‡ºå·²åœ¨GPUä¸Š
                t_feat = F.normalize(
                    scatter_mean_manual(
                        self.t_feat[self.word_tensor[1]],
                        self.word_tensor[0],
                        dim=0
                    )
                )
                feature_list.append(t_feat)
            else:
                feature_list.append(self.t_feat)

        # æ‹¼æ¥ç‰¹å¾
        if len(feature_list) == 0:
            # å¦‚æœæ²¡æœ‰ä»»ä½•ç‰¹å¾ï¼Œè¿”å›é›¶å‘é‡
            feature = torch.zeros(self.num_item, self.dim_E).cuda()
        else:
            feature = torch.cat(feature_list, dim=1)
            feature = F.leaky_relu(self.encoder_layer1(feature))
            feature = self.encoder_layer2(feature)

        return feature

    def get_neighbor_aggregation(self, users):
        """è·å–ç”¨æˆ·é‚»å±…çš„èšåˆç‰¹å¾å’Œå…±åŒç‰©å“çš„èšåˆç‰¹å¾"""
        batch_size = users.size(0)
        neighbor_embeds = []
        common_item_embeds = []

        feature = self.encoder()

        for i, user in enumerate(users):
            # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿user_idæ˜¯Python int
            user_id = int(user.item())

            # è·å–é‚»å±…ç”¨æˆ·
            neighbors = self.user_neighbors.get(user_id, [])

            if len(neighbors) > 0:
                # èšåˆé‚»å±…ç”¨æˆ·embedding (å–top-kä¸ª)
                k = min(10, len(neighbors))
                neighbor_ids = neighbors[:k]
                neighbor_embed = self.id_embedding[neighbor_ids].mean(dim=0)

                # æ‰¾å…±åŒç‰©å“
                common_items = set()
                for neighbor in neighbor_ids:
                    neighbor = int(neighbor)  # ğŸ”§ ç¡®ä¿æ˜¯int
                    if neighbor in self.user_items:
                        common_items.update(self.user_items[neighbor])

                # è¿‡æ»¤æ‰ç”¨æˆ·è‡ªå·±äº¤äº’è¿‡çš„ç‰©å“
                if user_id in self.user_items:
                    common_items -= self.user_items[user_id]

                common_items = list(common_items)[:20]  # æœ€å¤š20ä¸ªå…±åŒç‰©å“

                if len(common_items) > 0:
                    # èšåˆå…±åŒç‰©å“çš„ç‰¹å¾ - ä¿®å¤ç´¢å¼•é—®é¢˜
                    item_indices = []
                    for item in common_items:
                        item = int(item)  # ğŸ”§ ç¡®ä¿æ˜¯int
                        idx = item - self.num_user
                        # ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
                        if 0 <= idx < feature.size(0):
                            item_indices.append(idx)

                    if len(item_indices) > 0:
                        common_item_embed = feature[item_indices].mean(dim=0)
                    else:
                        common_item_embed = neighbor_embed.clone()
                else:
                    common_item_embed = neighbor_embed.clone()
            else:
                # æ²¡æœ‰é‚»å±…ï¼Œä½¿ç”¨ç”¨æˆ·è‡ªå·±çš„embedding
                neighbor_embed = self.id_embedding[user_id]
                common_item_embed = neighbor_embed.clone()

            neighbor_embeds.append(neighbor_embed)
            common_item_embeds.append(common_item_embed)

        neighbor_embeds = torch.stack(neighbor_embeds)
        common_item_embeds = torch.stack(common_item_embeds)

        return neighbor_embeds, common_item_embeds

    def loss_contrastive(self, tensor_anchor, tensor_all, temp_value):
        """åŸå§‹å¯¹æ¯”æŸå¤±"""
        all_score = torch.exp(torch.sum(tensor_anchor * tensor_all, dim=1) / temp_value).view(-1, 1 + self.num_neg)
        pos_score = all_score[:, 0]
        all_score = torch.sum(all_score, dim=1)

        # æ·»åŠ æ•°å€¼ç¨³å®šæ€§
        contrastive_loss = (-torch.log(pos_score / (all_score + 1e-8) + 1e-8)).mean()
        return contrastive_loss

    def loss_neighbor_item(self, neighbor_embed, item_embed, temp_value):
        """æ–°å¢ï¼šç”¨æˆ·é‚»å±… vs å…±åŒç‰©å“çš„å¯¹æ¯”æŸå¤±"""
        neighbor_embed = F.normalize(neighbor_embed, dim=1)
        item_embed = F.normalize(item_embed, dim=1)

        # è®¡ç®—ç›¸ä¼¼åº¦
        pos_score = torch.exp(torch.sum(neighbor_embed * item_embed, dim=1) / temp_value)

        # è´Ÿæ ·æœ¬ï¼šbatchå†…å…¶ä»–æ ·æœ¬
        neg_score = torch.exp(torch.matmul(neighbor_embed, item_embed.t()) / temp_value)
        neg_score = torch.sum(neg_score, dim=1) - pos_score  # æ’é™¤è‡ªå·±

        loss = -torch.log(pos_score / (pos_score + neg_score + 1e-8)).mean()
        return loss

    def forward(self, user_tensor, item_tensor):
        # å¤„ç†å¼ é‡å½¢çŠ¶
        pos_item_tensor = item_tensor[:, 0].unsqueeze(1)
        pos_item_tensor = pos_item_tensor.repeat(1, 1 + self.num_neg).view(-1, 1).squeeze()

        user_tensor_flat = user_tensor.view(-1, 1).squeeze()
        item_tensor_flat = item_tensor.view(-1, 1).squeeze()

        # è·å–å”¯ä¸€ç”¨æˆ·ï¼ˆç”¨äºé‚»å±…èšåˆï¼‰
        unique_users = user_tensor[:, 0]

        # ç¼–ç ç‰¹å¾
        feature = self.encoder()

        # ä¿®å¤ï¼šç¡®ä¿itemç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
        item_indices = item_tensor_flat - self.num_user
        valid_mask = (item_indices >= 0) & (item_indices < feature.size(0))

        if not valid_mask.all():
            print(f"Warning: Some item indices out of range. Valid: {valid_mask.sum()}/{len(valid_mask)}")
            item_indices = torch.clamp(item_indices, 0, feature.size(0) - 1)

        all_item_feat = feature[item_indices]

        # Embeddings
        user_embedding = self.id_embedding[user_tensor_flat]
        pos_item_embedding = self.id_embedding[pos_item_tensor]
        all_item_embedding = self.id_embedding[item_tensor_flat]

        # åŸå§‹å¯¹æ¯”æŸå¤±
        head_feat = F.normalize(all_item_feat, dim=1)
        head_embed = F.normalize(pos_item_embedding, dim=1)

        all_item_input = all_item_embedding.clone()
        num_to_replace = int(all_item_embedding.size(0) * self.num_sample)
        if num_to_replace > 0:
            # ğŸ”§ ä¿®å¤ï¼šç›´æ¥åœ¨GPUä¸Šç”Ÿæˆéšæœºç´¢å¼•ï¼Œé¿å…CPU->GPUä¼ è¾“
            rand_index = torch.randint(
                0, all_item_embedding.size(0), (num_to_replace,),
                device=all_item_embedding.device
            )
            # ğŸ”§ ä¿®å¤æ··åˆç²¾åº¦è®­ç»ƒçš„ç±»å‹ä¸åŒ¹é…é—®é¢˜
            all_item_input[rand_index] = all_item_feat[rand_index].to(all_item_input.dtype)

        self.contrastive_loss_1 = self.loss_contrastive(head_embed, head_feat, self.temp_value)
        self.contrastive_loss_2 = self.loss_contrastive(user_embedding, all_item_input, self.temp_value)

        # æ–°å¢ï¼šé‚»å±…-ç‰©å“å¯¹æ¯”æŸå¤±ï¼ˆå¯é€‰ï¼‰
        if self.use_neighbor_loss:
            try:
                neighbor_embeds, common_item_embeds = self.get_neighbor_aggregation(unique_users)
                self.neighbor_item_loss = self.loss_neighbor_item(neighbor_embeds, common_item_embeds, self.temp_value)
            except Exception as e:
                print(f"Warning: Neighbor aggregation failed: {e}")
                self.neighbor_item_loss = torch.tensor(0.0).cuda()
        else:
            # ç¦ç”¨é‚»å±…æŸå¤±ä»¥æå‡è®­ç»ƒé€Ÿåº¦
            self.neighbor_item_loss = torch.tensor(0.0).cuda()

        # æ­£åˆ™åŒ–
        reg_loss = ((torch.sqrt((user_embedding ** 2).sum(1))).mean() +
                    (torch.sqrt((all_item_embedding ** 2).sum(1))).mean()) / 2

        # æ›´æ–°result
        # ğŸ”§ ç¡®ä¿ç±»å‹ä¸€è‡´ä»¥æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ
        warm_embeddings = self.id_embedding[:self.num_user + self.num_warm_item]
        cold_features = feature[self.num_warm_item:].to(warm_embeddings.dtype)
        self.result = torch.cat((warm_embeddings, cold_features), dim=0)

        # æ€»æŸå¤±ï¼šåŸå§‹æŸå¤± + æ–°çš„é‚»å±…-ç‰©å“æŸå¤±
        total_loss = (self.contrastive_loss_1 * self.lr_lambda +
                      self.contrastive_loss_2 * (1 - self.lr_lambda) +
                      self.neighbor_item_loss * 0.1)  # 0.1æ˜¯æ–°æŸå¤±çš„æƒé‡

        return total_loss, reg_loss

    def loss(self, user_tensor, item_tensor):
        contrastive_loss, reg_loss = self.forward(user_tensor, item_tensor)
        reg_loss = self.reg_weight * reg_loss
        return reg_loss + contrastive_loss, self.contrastive_loss_2 + reg_loss, reg_loss